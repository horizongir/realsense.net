using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.Threading.Tasks;

namespace RealSense.Net
{
    /// <summary>
    /// Specifies the different types of data provided by RealSense devices.
    /// </summary>
    public enum Stream
    {
        /// <summary>
        /// Native stream of depth data produced by RealSense device.
        /// </summary>
        Depth,

        /// <summary>
        /// Native stream of color data captured by RealSense device.
        /// </summary>
        Color,

        /// <summary>
        /// Native stream of infrared data captured by RealSense device.
        /// </summary>
        Infrared,

        /// <summary>
        /// Native stream of infrared data captured from a second viewpoint by RealSense device.
        /// </summary>
        Infrared2,

        /// <summary>
        /// Native stream of fish-eye (wide) data captured from the dedicated motion camera.
        /// </summary>
        Fisheye,

        /// <summary>
        /// Synthetic stream containing point cloud data generated by deprojecting the depth image.
        /// </summary>
        Points,

        /// <summary>
        /// Synthetic stream containing undistorted color data with no extrinsic rotation from the depth stream.
        /// </summary>
        RectifiedColor,

        /// <summary>
        /// Synthetic stream containing color data but sharing intrinsics of depth stream.
        /// </summary>
        ColorAlignedToDepth,

        /// <summary>
        /// Synthetic stream containing second viewpoint infrared data but sharing intrinsics of depth stream.
        /// </summary>
        Infrared2AlignedToDepth,

        /// <summary>
        /// Synthetic stream containing depth data but sharing intrinsics of color stream.
        /// </summary>
        DepthAlignedToColor,

        /// <summary>
        /// Synthetic stream containing depth data but sharing intrinsics of rectified color stream.
        /// </summary>
        DepthAlignedToRectifiedColor,

        /// <summary>
        /// Synthetic stream containing depth data but sharing intrinsics of second viewpoint infrared stream.
        /// </summary>
        DepthAlignedToInfrared2
    }

    /// <summary>
    /// Specifies how a frame is represented in memory.
    /// </summary>
    public enum PixelFormat
    {
        /// <summary>
        /// When passed to enable stream, librealsense will try to provide best suited format.
        /// </summary>
        Any,

        /// <summary>
        /// 16-bit linear depth values. The depth is meters is equal to depth scale * pixel value.
        /// </summary>
        Z16,

        /// <summary>
        /// 16-bit linear disparity values. The depth in meters is equal to depth scale / pixel value.
        /// </summary>
        Disparity16,

        /// <summary>
        /// 32-bit floating point 3D coordinates.
        /// </summary>
        Xyz32f,

        /// <summary>
        /// Standard YUV pixel format as described in https://en.wikipedia.org/wiki/YUV.
        /// </summary>
        Yuyv,

        /// <summary>
        /// 8-bit red, green and blue channels.
        /// </summary>
        Rgb8,

        /// <summary>
        /// 8-bit blue, green, and red channels -- suitable for OpenCV.
        /// </summary>
        Bgr8,

        /// <summary>
        /// 8-bit red, green and blue channels + constant alpha channel equal to FF.
        /// </summary>
        Rgba8,

        /// <summary>
        /// 8-bit blue, green, and red channels + constant alpha channel equal to FF.
        /// </summary>
        Bgra8,

        /// <summary>
        /// 8-bit per-pixel grayscale image.
        /// </summary>
        Y8,

        /// <summary>
        /// 16-bit per-pixel grayscale image.
        /// </summary>
        Y16,

        /// <summary>
        /// Four 10-bit luminance values encoded into a 5-byte macropixel.
        /// </summary>
        Raw10,

        /// <summary>
        /// 16-bit raw image.
        /// </summary>
        Raw16,

        /// <summary>
        /// 8-bit raw image.
        /// </summary>
        Raw8
    }

    /// <summary>
    /// Specifies the layout of the output buffer used to store frame memory.
    /// </summary>
    public enum OutputBufferFormat
    {
        /// <summary>
        /// Makes sure that the output frame is exposed as a single continuous buffer.
        /// </summary>
        Continuous,

        /// <summary>
        /// Does not convert buffer to continuous. The user has to handle pitch manually.
        /// </summary>
        Native
    }

    /// <summary>
    /// Specifies general camera modes that can be translated by the API into concrete resolution and FPS.
    /// </summary>
    public enum Preset
    {
        /// <summary>
        /// Prefer best overall quality.
        /// </summary>
        BestQuality,

        /// <summary>
        /// Prefer largest image size.
        /// </summary>
        LargestImage,

        /// <summary>
        /// Prefer highest frame rate.
        /// </summary>
        HighestFramerate
    }

    /// <summary>
    /// Specifies which available hardware subdevices to start or stop.
    /// </summary>
    public enum Source
    {
        /// <summary>
        /// Video streaming of depth, infrared, color, or fish-eye.
        /// </summary>
        Video,

        /// <summary>
        /// Motion tracking from gyroscope and accelerometer.
        /// </summary>
        MotionTracking,

        /// <summary>
        /// Enable everything together.
        /// </summary>
        All
    }

    /// <summary>
    /// Specifies the distortion model defining how pixel coordinates should be mapped to sensor coordinates.
    /// </summary>
    public enum Distortion
    {
        /// <summary>
        /// Rectilinear images. No distortion compensation required.
        /// </summary>
        None,

        /// <summary>
        /// Equivalent to Brown-Conrady distortion, except that tangential distortion is applied to radially distorted points.
        /// </summary>
        ModifiedBrownConrady,

        /// <summary>
        /// Equivalent to Brown-Conrady distortion, except undistorts image instead of distorting it.
        /// </summary>
        InverseBrownConrady,

        /// <summary>
        /// Distortion model of the fish-eye camera.
        /// </summary>
        FTheta
    }

    /// <summary>
    /// Specifies optimized settings for different types of usage in SR300 devices.
    /// </summary>
    public enum IVCamPreset
    {
        /// <summary>
        /// Preset for short range.
        /// </summary>
        ShortRange,

        /// <summary>
        /// Preset for long range.
        /// </summary>
        LongRange,

        /// <summary>
        /// Preset for background segmentation.
        /// </summary>
        BackgroundSegmentation,

        /// <summary>
        /// Preset for gesture recognition.
        /// </summary>
        GestureRecognition,

        /// <summary>
        /// Preset for object scanning.
        /// </summary>
        ObjectScanning,

        /// <summary>
        /// Preset for face analytics.
        /// </summary>
        FaceAnalytics,

        /// <summary>
        /// Preset for face login.
        /// </summary>
        FaceLogin,

        /// <summary>
        /// Preset for GR cursor.
        /// </summary>
        GrCursor,

        /// <summary>
        /// Preset for default.
        /// </summary>
        Default,

        /// <summary>
        /// Preset for mid-range.
        /// </summary>
        MidRange,

        /// <summary>
        /// Preset for IR only.
        /// </summary>
        IrOnly
    }

    /// <summary>
    /// Specifies general device configuration controls.
    /// </summary>
    /// <remarks>
    /// These can generally be mapped to camera UVC controls, and unless stated otherwise,
    /// can be set or queried at any time.
    /// </remarks>
    public enum Option
    {
        /// <summary>
        /// Enable/disable color backlight compensation.
        /// </summary>
        ColorBacklightCompensation,

        /// <summary>
        /// Color image brightness.
        /// </summary>
        ColorBrightness,

        /// <summary>
        /// Color image contrast.
        /// </summary>
        ColorContrast,

        /// <summary>
        /// Controls exposure time of color camera. Setting any value will disable auto exposure.
        /// </summary>
        ColorExposure,

        /// <summary>
        /// Color image gain.
        /// </summary>
        ColorGain,

        /// <summary>
        /// Color image gamma setting.
        /// </summary>
        ColorGamma,

        /// <summary>
        /// Color image hue.
        /// </summary>
        ColorHue,

        /// <summary>
        /// Color image saturation setting.
        /// </summary>
        ColorSaturation,

        /// <summary>
        /// Color image sharpness setting.
        /// </summary>
        ColorSharpness,

        /// <summary>
        /// Controls white balance of color image. Setting any value will disable auto white balance.
        /// </summary>
        ColorWhiteBalance,

        /// <summary>
        /// Enable/disable color image auto-exposure.
        /// </summary>
        ColorEnableAutoExposure,

        /// <summary>
        /// Enable/disable color image auto-white-balance.
        /// </summary>
        ColorEnableAutoWhiteBalance,

        /// <summary>
        /// Power of the F200/SR300 projector, with 0 meaning projector off.
        /// </summary>
        F200LaserPower,

        /// <summary>
        /// Set the number of patterns projected per frame. The higher the accuracy value, the more patterns projected. Increasing the number of patterns helps to achieve better accuracy. Note that this control affects the depth FPS.
        /// </summary>
        F200Accuracy,

        /// <summary>
        /// Motion vs. range trade-off, with lower values allowing for better motion sensitivity and higher values allowing for better depth range.
        /// </summary>
        F200MotionRange,

        /// <summary>
        /// Set the filter to apply to each depth frame. Each one of the filters is optimized per the application requirements.
        /// </summary>
        F200FilterOption,

        /// <summary>
        /// Confidence level threshold used by the depth algorithm pipe to set whether a pixel will get a valid range or will be marked with invalid range.
        /// </summary>
        F200ConfidenceThreshold,

        /// <summary>
        /// (F200-only) Allows to reduce FPS without restarting streaming. Valid values are {2, 5, 15, 30, 60}.
        /// </summary>
        F200DynamicFps,

        /// <summary>
        /// Configures SR300 depth auto-range setting. Should not be used directly but through the \c rsApplyIvcamPreset method in rsutil.h.
        /// </summary>
        Sr300AutoRangeEnableMotionVersusRange,

        /// <summary>
        /// Configures SR300 depth auto-range setting. Should not be used directly but through the \c rsApplyIvcamPreset method in rsutil.h.
        /// </summary>
        Sr300AutoRangeEnableLaser,

        /// <summary>
        /// Configures SR300 depth auto-range setting. Should not be used directly but through the \c rsApplyIvcamPreset method in rsutil.h.
        /// </summary>
        Sr300AutoRangeMinMotionVersusRange,

        /// <summary>
        /// Configures SR300 depth auto-range setting. Should not be used directly but through the \c rsApplyIvcamPreset method in rsutil.h.
        /// </summary>
        Sr300AutoRangeMaxMotionVersusRange,

        /// <summary>
        /// Configures SR300 depth auto-range setting. Should not be used directly but through the \c rsApplyIvcamPreset method in rsutil.h.
        /// </summary>
        Sr300AutoRangeStartMotionVersusRange,

        /// <summary>
        /// Configures SR300 depth auto-range setting. Should not be used directly but through the \c rsApplyIvcamPreset method in rsutil.h.
        /// </summary>
        Sr300AutoRangeMinLaser,

        /// <summary>
        /// Configures SR300 depth auto-range setting. Should not be used directly but through the \c rsApplyIvcamPreset method in rsutil.h.
        /// </summary>
        Sr300AutoRangeMaxLaser,

        /// <summary>
        /// Configures SR300 depth auto-range setting. Should not be used directly but through the \c rsApplyIvcamPreset method in rsutil.h.
        /// </summary>
        Sr300AutoRangeStartLaser,

        /// <summary>
        /// Configures SR300 depth auto-range setting. Should not be used directly but through the \c rsApplyIvcamPreset method in rsutil.h.
        /// </summary>
        Sr300AutoRangeUpperThreshold,

        /// <summary>
        /// Configures SR300 depth auto-range setting. Should not be used directly but through the \c rsApplyIvcamPreset method in rsutil.h.
        /// </summary>
        Sr300AutoRangeLowerThreshold,

        /// <summary>
        /// Enable/disable R200 auto-exposure. This will affect both the IR and depth images.
        /// </summary>
        R200LrAutoExposureEnabled,

        /// <summary>
        /// IR image gain.
        /// </summary>
        R200LrGain,

        /// <summary>
        /// This control allows manual adjustment of the exposure time value for the L/R imagers.
        /// </summary>
        R200LrExposure,

        /// <summary>
        /// Enables/disables R200 emitter.
        /// </summary>
        R200EmitterEnabled,

        /// <summary>
        /// Micrometers per increment in integer depth values. 1000 is default (mm scale). Set before streaming.
        /// </summary>
        R200DepthUnits,

        /// <summary>
        /// Minimum depth in current depth units that will be output. Any values less than ג€˜Min Depthג€™ will be mapped to 0 during the conversion between disparity and depth. Set before streaming.
        /// </summary>
        R200DepthClampMin,

        /// <summary>
        /// Maximum depth in current depth units that will be output. Any values greater than ג€˜Max Depthג€™ will be mapped to 0 during the conversion between disparity and depth. Set before streaming.
        /// </summary>
        R200DepthClampMax,

        /// <summary>
        /// Disparity scale factor used when in disparity output mode. Can only be set before streaming.
        /// </summary>
        R200DisparityMultiplier,

        /// <summary>
        /// {0 - 512}. Can only be set before streaming starts.
        /// </summary>
        R200DisparityShift,

        /// <summary>
        /// Mean intensity set point. Requires the \c R200LRAUTOEXPOSUREENABLED option to be set to 1.
        /// </summary>
        R200AutoExposureMeanIntensitySetPoint,

        /// <summary>
        /// Bright ratio set point. Requires the \c R200LRAUTOEXPOSUREENABLED option to be set to 1.
        /// </summary>
        R200AutoExposureBrightRatioSetPoint,

        /// <summary>
        /// Kp gain. Requires the \c R200LRAUTOEXPOSUREENABLED option to be set to 1.
        /// </summary>
        R200AutoExposureKpGain,

        /// <summary>
        /// Kp exposure. Requires the \c R200LRAUTOEXPOSUREENABLED option to be set to 1.
        /// </summary>
        R200AutoExposureKpExposure,

        /// <summary>
        /// Kp dark threshold. Requires the \c R200LRAUTOEXPOSUREENABLED option to be set to 1.
        /// </summary>
        R200AutoExposureKpDarkThreshold,

        /// <summary>
        /// Auto-exposure region-of-interest top edge (in pixels). Requires the \c R200LRAUTOEXPOSUREENABLED option to be set to 1.
        /// </summary>
        R200AutoExposureTopEdge,

        /// <summary>
        /// Auto-exposure region-of-interest bottom edge (in pixels). Requires the \c R200LRAUTOEXPOSUREENABLED option to be set to 1.
        /// </summary>
        R200AutoExposureBottomEdge,

        /// <summary>
        /// Auto-exposure region-of-interest left edge (in pixels). Requires the \c R200LRAUTOEXPOSUREENABLED option to be set to 1.
        /// </summary>
        R200AutoExposureLeftEdge,

        /// <summary>
        /// Auto-exposure region-of-interest right edge (in pixels). Requires the \c R200LRAUTOEXPOSUREENABLED option to be set to 1.
        /// </summary>
        R200AutoExposureRightEdge,

        /// <summary>
        /// Value to subtract when estimating the median of the correlation surface.
        /// </summary>
        R200DepthControlEstimateMedianDecrement,

        /// <summary>
        /// Value to add when estimating the median of the correlation surface.
        /// </summary>
        R200DepthControlEstimateMedianIncrement,

        /// <summary>
        /// Threshold: by how much the winning score exceeds the median.
        /// </summary>
        R200DepthControlMedianThreshold,

        /// <summary>
        /// Minimum correlation score that is considered acceptable.
        /// </summary>
        R200DepthControlScoreMinimumThreshold,

        /// <summary>
        /// Maximum correlation score that is considered acceptable.
        /// </summary>
        R200DepthControlScoreMaximumThreshold,

        /// <summary>
        /// Parameter for determining whether the texture in the region is sufficient to justify a depth result.
        /// </summary>
        R200DepthControlTextureCountThreshold,

        /// <summary>
        /// Parameter for determining whether the texture in the region is sufficient to justify a depth result.
        /// </summary>
        R200DepthControlTextureDifferenceThreshold,

        /// <summary>
        /// Threshold: how much the minimum correlation score must differ from the next best score.
        /// </summary>
        R200DepthControlSecondPeakThreshold,

        /// <summary>
        /// Neighbor threshold value for depth calculation.
        /// </summary>
        R200DepthControlNeighborThreshold,

        /// <summary>
        /// Left-right threshold value for depth calculation.
        /// </summary>
        R200DepthControlLRThreshold,

        /// <summary>
        /// Fisheye image exposure time in msec.
        /// </summary>
        FisheyeExposure,

        /// <summary>
        /// Fisheye image gain.
        /// </summary>
        FisheyeGain,

        /// <summary>
        /// Enable/disable fisheye strobe. When enabled, aligns timestamps to common clock-domain with the motion events.
        /// </summary>
        FisheyeStrobe,

        /// <summary>
        /// Enable/disable fisheye external trigger mode. When enabled, fisheye image will be aquired in-sync with the depth image.
        /// </summary>
        FisheyeExternalTrigger,

        /// <summary>
        /// Enable/disable fisheye auto-exposure.
        /// </summary>
        FisheyeEnableAutoExposure,

        /// <summary>
        /// 0 - static auto-exposure, 1 - anti-flicker auto-exposure, 2 - hybrid.
        /// </summary>
        FisheyeAutoExposureMode,

        /// <summary>
        /// Fisheye auto-exposure anti-flicker rate. Can be 50 or 60 Hz.
        /// </summary>
        FisheyeAutoExposureAntiflickerRate,

        /// <summary>
        /// In Fisheye auto-exposure sample frame every given number of pixels.
        /// </summary>
        FisheyeAutoExposurePixelSampleRate,

        /// <summary>
        /// In Fisheye auto-exposure sample every given number of frames.
        /// </summary>
        FisheyeAutoExposureSkipFrames,

        /// <summary>
        /// Number of frames the user is allowed to keep per stream. Trying to hold on to more frames will cause frame-drops.
        /// </summary>
        FramesQueueSize,

        /// <summary>
        /// Enable/disable fetching log data from the device.
        /// </summary>
        HardwareLoggerEnabled,

        /// <summary>
        /// Total number of detected frame drops from all streams.
        /// </summary>
        TotalFrameDrops
    }

    /// <summary>
    /// Specifies the types of value provided from the device with each frame.
    /// </summary>
    public enum FrameMetadata
    {
        /// <summary>
        /// Actual exposure at which the frame was captured.
        /// </summary>
        ActualExposure,

        /// <summary>
        /// Actual FPS at the time of capture.
        /// </summary>
        ActualFps
    }

    /// <summary>
    /// Specifies various capabilities of a RealSense device.
    /// </summary>
    public enum Capabilities
    {
        /// <summary>
        /// Provides depth stream.
        /// </summary>
        Depth,

        /// <summary>
        /// Provides color stream.
        /// </summary>
        Color,

        /// <summary>
        /// Provides infrared stream.
        /// </summary>
        Infrared,

        /// <summary>
        /// Provides second infrared stream.
        /// </summary>
        Infrared2,

        /// <summary>
        /// Provides wide field of view (fish-eye) stream.
        /// </summary>
        FishEye,

        /// <summary>
        /// Provides gyroscope and accelorometer events.
        /// </summary>
        MotionEvents,

        /// <summary>
        /// Provides method for upgrading motion module firmware.
        /// </summary>
        MotionModuleFwUpdate,

        /// <summary>
        /// Internally MIPI-to-USB adapter.
        /// </summary>
        AdapterBoard,

        /// <summary>
        /// Provides enough basic functionality to be considered supported. This is to catch at runtime various outdated engineering samples.
        /// </summary>
        Enumeration
    }

    /// <summary>
    /// Specifies proprietary formats for direct communication with the device firmware.
    /// </summary>
    public enum BlobType
    {
        /// <summary>
        /// By using this option, new firmware can be uploaded to the ZR300 motion-module.
        /// </summary>
        MotionModuleFirmwareUpdate
    }

    /// <summary>
    /// Specifies several read-only strings that can be queried from the device.
    /// </summary>
    /// <remarks>
    /// Not all information fields are available on all camera types. This information is
    /// mainly available for camera debug and troubleshooting and should not be used in applications.
    /// </remarks>
    public enum CameraInfo
    {
        /// <summary>
        /// Device friendly name.
        /// </summary>
        DeviceName,

        /// <summary>
        /// Device serial number.
        /// </summary>
        DeviceSerialNumber,

        /// <summary>
        /// Primary firmware version.
        /// </summary>
        CameraFirmwareVersion,

        /// <summary>
        /// MIPI-to-USB adapter board firmware version if such board is present.
        /// </summary>
        AdapterBoardFirmwareVersion,

        /// <summary>
        /// Motion module firmware version if motion module is present.
        /// </summary>
        MotionModuleFirmwareVersion,

        /// <summary>
        /// R200/LR200/ZR300 camera type.
        /// </summary>
        CameraType,

        /// <summary>
        /// OEM ID.
        /// </summary>
        OemId,

        /// <summary>
        /// ISP firmware version, when available.
        /// </summary>
        IspFwVersion,

        /// <summary>
        /// R200/LR200/ZR300 content version.
        /// </summary>
        ContentVersion,

        /// <summary>
        /// R200/LR200/ZR300 module version.
        /// </summary>
        ModuleVersion,

        /// <summary>
        /// Primary imager model number.
        /// </summary>
        ImagerModelNumber,

        /// <summary>
        /// Device build date.
        /// </summary>
        BuildDate,

        /// <summary>
        /// Primary calibration date.
        /// </summary>
        CalibrationDate,

        /// <summary>
        /// R200/LR200/ZR300 program date.
        /// </summary>
        ProgramDate,

        /// <summary>
        /// Focus calibration date.
        /// </summary>
        FocusAlignmentDate,

        /// <summary>
        /// R200/LR200/ZR300 emitter type.
        /// </summary>
        EmitterType,

        /// <summary>
        /// Result of the focus calibration.
        /// </summary>
        FocusValue,

        /// <summary>
        /// Primary lens type.
        /// </summary>
        LensType,

        /// <summary>
        /// Color imager lens type.
        /// </summary>
        ColorLensType,

        /// <summary>
        /// Lens coating type.
        /// </summary>
        LensCoatingType,

        /// <summary>
        /// Color coating type.
        /// </summary>
        ColorLensCoatingType,

        /// <summary>
        /// Nominal baseline.
        /// </summary>
        NominalBaseline,

        /// <summary>
        /// Color nominal baseline.
        /// </summary>
        ColorNominalBaseline
    }

    /// <summary>
    /// Specifies the severity of the API logger.
    /// </summary>
    public enum LogSeverity
    {
        /// <summary>
        /// Detailed information about ordinary operations.
        /// </summary>
        Debug,

        /// <summary>
        /// Terse information about ordinary operations.
        /// </summary>
        Info,

        /// <summary>
        /// Indication of possible failure.
        /// </summary>
        Warn,

        /// <summary>
        /// Indication of definite failure.
        /// </summary>
        Error,

        /// <summary>
        /// Indication of unrecoverable failure.
        /// </summary>
        Fatal,

        /// <summary>
        /// No logging will occur.
        /// </summary>
        None
    }

    /// <summary>
    /// Specifies the source device that triggered a specific timestamp event from the motion module.
    /// </summary>
    public enum EventSource
    {
        /// <summary>
        /// Event from accelerometer.
        /// </summary>
        ImuAccel,

        /// <summary>
        /// Event from the gyroscope.
        /// </summary>
        ImuGyro,

        /// <summary>
        /// Event from depth camera (depth/IR frame).
        /// </summary>
        ImuDepthCam,

        /// <summary>
        /// Event from the fish-eye camera.
        /// </summary>
        ImuMotionCam,

        /// <summary>
        /// Event from external GPIO 0.
        /// </summary>
        G0Sync,

        /// <summary>
        /// Event from external GPIO 1.
        /// </summary>
        G1Sync,

        /// <summary>
        /// Event from external GPIO 2.
        /// </summary>
        G2Sync
    }

    /// <summary>
    /// Specifies the clock in relation to which the frame timestamp was measured.
    /// </summary>
    /// <remarks>
    /// When working with a motion microcontroller, motion data timestamps are always in the microcontroller timestamp domain.
    /// Some frames, however, might not successfully receive microcontroller timestamps and will be marked as camera domain.
    /// </remarks>
    public enum TimestampDomain
    {
        /// <summary>
        /// Frame timestamp was measured in relation to the camera clock.
        /// </summary>
        Camera,

        /// <summary>
        /// Frame timestamp was measured in relation to the microcontroller clock.
        /// </summary>
        Microcontroller
    }

    /// <summary>
    /// Represents the method that will be invoked whenever a new frame arrives.
    /// </summary>
    /// <param name="frame">The frame data object.</param>
    public delegate void FrameCallback(Frame frame);

    /// <summary>
    /// Represents the method that will be invoked whenever new motion data arrives.
    /// </summary>
    /// <param name="entry">The motion data object.</param>
    public delegate void MotionCallback(MotionData entry);

    /// <summary>
    /// Represents the method that will be invoked whenever new timestamp data arrives.
    /// </summary>
    /// <param name="entry">The timestamp data object.</param>
    public delegate void TimestampCallback(TimestampData entry);

    /// <summary>
    /// Represents the method that will be invoked whenever a new message needs to be logged.
    /// </summary>
    /// <param name="severity">The severity of the logged message.</param>
    /// <param name="message">The message to be logged.</param>
    public delegate void LogCallback(LogSeverity severity, string message);
}
